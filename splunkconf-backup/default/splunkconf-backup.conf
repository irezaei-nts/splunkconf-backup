#[settings]

# this file to overwrite defautl in scripts
# located under /opt/splunk/scripts/backup/ENVSPLBACKUP
# 20170606 changed default backups directory to be in splunk_home/var as more chance to have room in it
# 20180619 split backup parameters in distinct conf file to isolate backup parameters and move backup script to subdirectory
# 20180619 add distinct local and remote purge settings, add parameters for remote backup (nas, s3, ...)
# 20180619 move content to script under default in order to have a clean view on modified settings here

# this file is being included in script (bash)
# please override only the local in local as usual 


# splunkconf backup
#

# backup type selection 
# 1 = targeted etc -> use a list of directories and files to backup
# 2 = full etc   (bigger)
# default to targeted etc
BACKUPTYPE=1

# LOCAL AND REMOTE BACKUP options

# LOCAL options
# NOT used this is enforced ! DOLOCALBACKUP=1
# type : 1 = date versioned backup (preferred for local),2 = only one backup file with instance name in it (dangerous, we need other feature to do versioning like filesystem (btrfs) , classic backup on top, ...  3 = only one backup, no instance name in it (tehy are still sorted by instance directory, may be easier for automatic reuse by install scripts)
LOCALTYPE=1
# where to store local backups
# depending on partitions
# splunk user should be able to write to this directory
LOCALBACKUPDIR="${SPLUNK_HOME}/var/backups"
# Reserve enough space or backups will fail ! IMPORTANT
# see below for check on min free space

# REMOTE options
# enabled by default , try to get s3 bucket info from ec2 tags or just do nothing
DOREMOTEBACKUP=1
# exemple, please tune
# PLEASE USE A SUBDIRECTORY ON THE REMOTE LOCATION SO THAT THE DIRECTORY CHECK WILL FAIL IN CASE THE REMOTE STORAGE IS NOT THERE (we don't want to write locally if not mouted for example)
#REMOTEBACKUPDIR="/mnt/remotenas/backup"
REMOTEBACKUPDIR="s3://pleaseconfigureec2tagsorsetdirectlythes3bucketforbackupshere-s3splunkbackup/splunkconf-backup"
# type 1 = nas (use cp), 2 = S3 (use aws s3 cp), 3= remote nas via scp
REMOTETECHNO=2
# type : 0=auto 1 = date versioned backup (preferred for local),2 = only one backup file (dangerous, we need other feature to do versioning like filesystem (btrfs) , classic backup on top, ... 3 = only one backup, no instance name in it (they are still sorted by instance directory, may be easier for automatic reuse by install scripts)
# auto -> S3 =0 (because s3 can store multiple versions of same file), NAS=1
REMOTETYPE=0

# WHAT TO BACKUP
# this can be used for : rollback, doing diff , moving conf to new server, ....
# this is not meant to backup files binaries, var , index, ....
# you should backup the backup ie not just keep it local to avoid the server has crashed and the script deleting the backups....
# set to activate backups
BACKUP=1
# set to backup kvstore
BACKUPKV=1
# set to backup scheduler state, modinput (hf but also useful on sh for dm and throttling) 
BACKUPSTATE=1
# set to backup scripts
BACKUPSCRIPTS=1


# KVSTORE Backup options
# stop splunk for kvstore backup (that can be a bad idea if you have cluster and stop all instances at same time or whitout maintenance mode)
# risk is that data could be corrupted if something is written to kvstore while we do the backup
#RESTARTFORKVBACKUP=1
# default path, change if you need, especially if you customized splunk_db
KVDBPATH="${SPLUNK_DB}/kvstore"

# fixme : move this after so that splunk_home changes apply
# state files and dir
MODINPUTPATH="${SPLUNK_DB}/modinput"
SCHEDULERSTATEPATH="${SPLUNK_HOME}/var/run/splunk/scheduler"
STATELIST="${SPLUNK_HOME}/var/run/splunk/cluster/remote-bundle ${SPLUNK_DB}/persistentstorage ${SPLUNK_DB}/fishbucket ${SPLUNK_HOME}/var/run/splunk/deploy"

# configuration for scripts backups
# script dir (what to backup)
SCRIPTDIR="${SPLUNK_HOME}/scripts"

#minfreespace

# 5000000 = 5G
# more than splunk daemon limit so that we hopefully stop doing backups before splunk reach his own limit (5G by default)
# obviously if you have done the right sizing for backups, the other constraint should win first as we could be in a situation of disk starvation preventing any launch of backup for a while
MINFREESPACE=6000000


##### LOCAL

LOCALBACKUPDIR="${SPLUNK_HOME}/var/backups"

# number of days after which we completely remove backups
LOCALBACKUPRETENTIONDAYS=20
# number of days after which we remove most backups to free up space (this should be under the first parameter)
# idea is that we may have a high frequency backup for recent ones then we only keep a few (just in case, we want to go back to a old situation)
# NOT YET IMPLEMENTED
LOCALBACKUPRETENTIONDAYSPARTIAL=180
# KV
LOCALBACKUPKVRETENTIONDAYS=20
# scripts
LOCALBACKUPSCRIPTSRETENTIONDAYS=100
# modinput/state
LOCALBACKUPMODINPUTRETENTIONDAYS=7
LOCALBACKUPSTATERETENTIONDAYS=7

LOCALMAXSIZE=7200000000 
#4G
#LOCALMAXSIZE=2000000000 #2G

##### REMOTE 
# number of days after which we completely remove backups
REMOTEBACKUPRETENTIONDAYS=180
# number of days after which we remove most backups to free up space (this should be under the first parameter)
# idea is that we may have a high frequency backup for recent ones then we only keep a few (just in case, we want to go back to a old situation)
# NOT YET IMPLEMENTED
REMOTEBACKUPRETENTIONDAYSPARTIAL=180
# KV
REMOTEBACKUPKVRETENTIONDAYS=60
# scripts
REMOTEBACKUPSCRIPTSRETENTIONDAYS=200
# modinput
REMOTEBACKUPMODINPUTRETENTIONDAYS=7
REMOTEBACKUPSTATERETENTIONDAYS=7

REMOTEMAXSIZE=100000000000 #100G




